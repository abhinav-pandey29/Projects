{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The raw data files and their format\n",
    "\n",
    "While the rate of fatal road accidents has been decreasing steadily since the 80s, the past ten years have seen a stagnation in this reduction.\n",
    "\n",
    "By looking at the demographics of traﬃc accident victims for each US state, we find that there is a lot of variation between states. Now we want to understand if there are patterns in this variation in order to derive suggestions for a policy action plan. In particular, instead of implementing a costly nation-wide plan we want to focus on groups of  states with similar profiles. **How can we find such groups in a statistically sound way and communicate the result effectively?**\n",
    "\n",
    "The data given to us was originally collected by the National Highway Traffic Safety Administration and the National Association of Insurance Commissioners. This particular dataset was compiled and released as a <a href=\"https://github.com/fivethirtyeight/data/tree/master/bad-drivers\">CSV-file</a> by FiveThirtyEight under the <a href=\"https://github.com/ﬁvethirtyeight/data\">CC-BY4.0 license"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "dc": {
     "key": "3"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/c/Users/Pandey/Desktop/Mini Project 3']\n",
      "['Untitled.ipynb', 'datasets', 'notebook.ipynb']\n",
      "['miles-driven.csv', 'road-accidents.csv']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['##### LICENSE #####',\n",
       " '# This data set is modified from the original at fivethirtyeight (https://github.com/fivethirtyeight/data/tree/master/bad-drivers)',\n",
       " '# and it is released under CC BY 4.0 (https://creativecommons.org/licenses/by/4.0/)',\n",
       " '##### COLUMN ABBREVIATIONS #####',\n",
       " '# drvr_fatl_col_bmiles = Number of drivers involved in fatal collisions per billion miles (2011)',\n",
       " '# perc_fatl_speed = Percentage Of Drivers Involved In Fatal Collisions Who Were Speeding (2009)',\n",
       " '# perc_fatl_alcohol = Percentage Of Drivers Involved In Fatal Collisions Who Were Alcohol-Impaired (2011)',\n",
       " '# perc_fatl_1st_time = Percentage Of Drivers Involved In Fatal Collisions Who Had Not Been Involved In Any Previous Accidents (2011)',\n",
       " '##### DATA BEGIN #####',\n",
       " 'state|drvr_fatl_col_bmiles|perc_fatl_speed|perc_fatl_alcohol|perc_fatl_1st_time',\n",
       " 'Alabama|18.8|39|30|80',\n",
       " 'Alaska|18.1|41|25|94',\n",
       " 'Arizona|18.6|35|28|96',\n",
       " 'Arkansas|22.4|18|26|95',\n",
       " 'California|12|35|28|89',\n",
       " 'Colorado|13.6|37|28|95',\n",
       " 'Connecticut|10.8|46|36|82',\n",
       " 'Delaware|16.2|38|30|99',\n",
       " 'District of Columbia|5.9|34|27|100',\n",
       " 'Florida|17.9|21|29|94']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the name of the current folder\n",
    "current_dir = !pwd\n",
    "print(current_dir)\n",
    "\n",
    "# List all files in this folder\n",
    "file_list = !ls\n",
    "print(file_list)\n",
    "\n",
    "# List all files in the datasets directory\n",
    "dataset_list = !ls \"datasets/\"\n",
    "print(dataset_list)\n",
    "\n",
    "# View the first 20 lines of datasets/road-accidents.csv\n",
    "accidents_head = !head -20 \"datasets/road-accidents.csv\" \n",
    "accidents_head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Read in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "dc": {
     "key": "10"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 51 rows and 5 columns.\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 51 entries, 0 to 50\n",
      "Data columns (total 5 columns):\n",
      "state            51 non-null object\n",
      "FatalAcc_PBM     51 non-null float64\n",
      "Speeding_Perc    51 non-null int64\n",
      "DUI_Perc         51 non-null int64\n",
      "1st_Time_Perc    51 non-null int64\n",
      "dtypes: float64(1), int64(3), object(1)\n",
      "memory usage: 2.1+ KB\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>FatalAcc_PBM</th>\n",
       "      <th>Speeding_Perc</th>\n",
       "      <th>DUI_Perc</th>\n",
       "      <th>1st_Time_Perc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>12.7</td>\n",
       "      <td>19</td>\n",
       "      <td>27</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>Washington</td>\n",
       "      <td>10.6</td>\n",
       "      <td>42</td>\n",
       "      <td>33</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>West Virginia</td>\n",
       "      <td>23.8</td>\n",
       "      <td>34</td>\n",
       "      <td>28</td>\n",
       "      <td>87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>13.8</td>\n",
       "      <td>36</td>\n",
       "      <td>33</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>Wyoming</td>\n",
       "      <td>17.4</td>\n",
       "      <td>42</td>\n",
       "      <td>32</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            state  FatalAcc_PBM  Speeding_Perc  DUI_Perc  1st_Time_Perc\n",
       "46       Virginia          12.7             19        27             88\n",
       "47     Washington          10.6             42        33             86\n",
       "48  West Virginia          23.8             34        28             87\n",
       "49      Wisconsin          13.8             36        33             84\n",
       "50        Wyoming          17.4             42        32             90"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the `pandas` module as \"pd\"\n",
    "import pandas as pd\n",
    "\n",
    "# Read in `road-accidents.csv`\n",
    "car_acc = pd.read_csv('datasets/road-accidents.csv', delimiter=\"|\", header=9 )\n",
    "\n",
    "# Save the number of rows columns as a tuple\n",
    "rows_and_cols = car_acc.shape\n",
    "print('There are {} rows and {} columns.\\n'.format(\n",
    "    rows_and_cols[0], rows_and_cols[1]))\n",
    "\n",
    "car_acc.columns = ['state', 'FatalAcc_PBM', 'Speeding_Perc', 'DUI_Perc', '1st_Time_Perc']\n",
    "\n",
    "# Generate an overview of the DataFrame\n",
    "car_acc_information = car_acc.info()\n",
    "print(car_acc_information)\n",
    "\n",
    "# Display the last five rows of the DataFrame\n",
    "car_acc.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Summarize data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "17"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       FatalAcc_PBM  Speeding_Perc   DUI_Perc  1st_Time_Perc\n",
      "count     51.000000      51.000000  51.000000       51.00000\n",
      "mean      15.790196      31.725490  30.686275       88.72549\n",
      "std        4.122002       9.633438   5.132213        6.96011\n",
      "min        5.900000      13.000000  16.000000       76.00000\n",
      "25%       12.750000      23.000000  28.000000       83.50000\n",
      "50%       15.600000      34.000000  30.000000       88.00000\n",
      "75%       18.500000      38.000000  33.000000       95.00000\n",
      "max       23.900000      54.000000  44.000000      100.00000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x1c9983d6d48>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import seaborn and make plots appear inline\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Compute the summary statistics of all columns in the `car_acc` DataFrame\n",
    "sum_stat_car = car_acc.describe()\n",
    "print(sum_stat_car)\n",
    "\n",
    "# Create a pairwise scatter plot to explore the data\n",
    "sns.pairplot(car_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "24"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Compute the correlation coefficent for all column pairs\n",
    "corr_columns = car_acc.corr()\n",
    "corr_columns\n",
    "\n",
    "ax=sns.heatmap(corr_columns, annot=True)\n",
    "bottom, top = ax.get_ylim()\n",
    "ax.set_ylim(bottom + 0.5, top - 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Feature importance\n",
    "\n",
    "Using linear regression coefficients we can estimate feature importances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "31"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Import the linear model function from sklearn\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Create the features and target DataFrames\n",
    "features = car_acc.drop(['state','FatalAcc_PBM'], axis=1)\n",
    "target = car_acc['FatalAcc_PBM']\n",
    "\n",
    "# Create a linear regression object\n",
    "reg = linear_model.LinearRegression()\n",
    "\n",
    "# Fit a multivariate linear regression model\n",
    "reg.fit(features, target)\n",
    "\n",
    "# Retrieve the regression coefficients\n",
    "fit_coef = reg.coef_\n",
    "fit_coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Perform PCA on standardized data\n",
    "\n",
    "We have learned that alcohol consumption is weakly associated with the number of fatal accidents across states. This could lead us to conclude that alcohol consumption should be a focus for further investigations and maybe strategies should divide states into high versus low alcohol consumption in accidents. But there are also associations between  alcohol consumptions and the other two features, so it might be worth trying to split the states in a way that accounts for all three features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "38"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Standardize and center the feature columns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Import the PCA class function from sklearn\n",
    "from sklearn.decomposition import PCA\n",
    "pca = PCA()\n",
    "\n",
    "# Fit the standardized data to the pca\n",
    "pca.fit(features_scaled)\n",
    "\n",
    "# Plot the proportion of variance explained on the y-axis of the bar plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.bar(range(1, pca.n_components_ + 1),  pca.explained_variance_ratio_)\n",
    "plt.xlabel('Principal component #')\n",
    "plt.ylabel('Proportion of variance explained')\n",
    "plt.xticks([1, 2, 3])\n",
    "\n",
    "# Compute the cumulative proportion of variance explained by the first two principal components\n",
    "two_first_comp_var_exp = pca.explained_variance_ratio_.cumsum()[1]\n",
    "print(\"The cumulative variance of the first two principal components is {}\".format(\n",
    "    round(two_first_comp_var_exp, 5)))\n",
    "\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize the first two principal components\n",
    "\n",
    "The first two principal components enable visualization of the data in two dimensions while capturing a high proportion of the variation (79%) from all three features: speeding, alcohol influence, and first-time accidents.\n",
    "\n",
    "We will create a scatter plot of the first principle components and explore how the states cluster together in this visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "45"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Transform the scaled features using two principal components\n",
    "pca = PCA(n_components=2)\n",
    "p_comps = pca.fit_transform(features_scaled)\n",
    "\n",
    "# Extract the first and second component to use for the scatter plot\n",
    "p_comp1 = p_comps[:,0]\n",
    "p_comp2 = p_comps[:,1]\n",
    "\n",
    "# Plot the first two principal components in a scatter plot\n",
    "plt.scatter(p_comp1, p_comp2)\n",
    "plt.title(\"Fatal Collisions in the United States\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Find clusters of similar states in the data\n",
    "\n",
    "To identify how many groups exist we will use KMeans Unsupervised CLustering. \n",
    "\n",
    "To identify a reasonable number of clusters, we can use KMeans clustering by creating a scatter plot and finding the \"elbow\", which is an indication of when the addition of more clusters does not add much explanatory power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "52"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Import KMeans from sklearn\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# A loop will be used to plot the explanatory power for up to 10 KMeans clusters\n",
    "ks = range(1, 10)\n",
    "inertias = []\n",
    "for k in ks:\n",
    "    # Initialize the KMeans object using the current number of clusters (k)\n",
    "    km = KMeans(n_clusters=k, random_state=8)\n",
    "    # Fit the scaled features to the KMeans object\n",
    "    km.fit(features_scaled)\n",
    "    # Append the inertia for `km` to the list of inertias\n",
    "    inertias.append(km.inertia_)\n",
    "    \n",
    "# Plot the results in a line plot\n",
    "plt.plot(ks, inertias, marker='o')\n",
    "plt.xlabel(\"Number of Clusters\")\n",
    "plt.ylabel(\"Within Cluster Sum of Squares\")\n",
    "plt.title(\"Elbow Method\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. KMeans to visualize clusters in the PCA scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "59"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Create a KMeans object with 3 clusters\n",
    "km = KMeans(n_clusters=3, random_state=8)\n",
    "\n",
    "# Fit the data to the `km` object\n",
    "km.fit(features_scaled)\n",
    "\n",
    "# Create a scatter plot of the first two principal components\n",
    "# and color it according to the KMeans cluster assignment \n",
    "plt.scatter(p_comps[:, 0], p_comps[:, 1], c=km.labels_)\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.title(\"K-Means Clustering\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Visualize the feature differences between the clusters\n",
    "\n",
    "The next step in our analysis is to explore how the three clusters are different in terms of the three features that we used for clustering. Instead of using the scaled features, we return to using the unscaled features to help us interpret the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "66"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Create a new column with the labels from the KMeans clustering\n",
    "car_acc['cluster'] = km.labels_\n",
    "\n",
    "# Reshape the DataFrame to the long format\n",
    "melt_car = pd.melt(car_acc, id_vars='cluster', var_name='measurement',\n",
    "                  value_name='percent', value_vars=features.columns)\n",
    "\n",
    "# Create a violin plot splitting and coloring the results according to the km-clusters\n",
    "sns.violinplot(data=melt_car,x='measurement', y='percent')\n",
    "plt.title(\"Percentage of Drivers involved in Fatal Collisions (Overall)\")\n",
    "plt.ylabel(\"Percentage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Compute the number of accidents within each cluster\n",
    "\n",
    "Different groups of states may require different interventions. Since resources and time are limited, it is useful to start off with an intervention in one of the three groups first.\n",
    "\n",
    "To count the EXACT NUMBER of FATAL collisions we will use the data of number of miles driven in each state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "dc": {
     "key": "73"
    },
    "tags": [
     "sample_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Read in the new dataset\n",
    "miles_driven = pd.read_csv('datasets/miles-driven.csv', sep='|')\n",
    "\n",
    "# Merge the `car_acc` DataFrame with the `miles_driven` DataFrame\n",
    "car_acc_miles = car_acc.merge(miles_driven, on='state')\n",
    "\n",
    "# Create a new column for the number of drivers involved in fatal accidents\n",
    "car_acc_miles['num_Fatal'] = car_acc_miles['FatalAcc_PBM']*car_acc_miles['million_miles_annually']/1000\n",
    "\n",
    "# Create a barplot of the total number of accidents per cluster\n",
    "sns.barplot(x='cluster', y='num_Fatal', data=car_acc_miles, estimator=sum, ci=None)\n",
    "plt.title(\"Number of Accidents in each cluster\")\n",
    "\n",
    "# Calculate the number of states in each cluster and their 'num_drvr_fatl_col' mean and sum.\n",
    "count_mean_sum = car_acc_miles.groupby('cluster').agg(['count', 'mean', 'sum'])['num_Fatal']\n",
    "count_mean_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Make a decision when there is no clear right choice\n",
    "\n",
    "As we can see, there is no obvious correct choice regarding which cluster is the most important to focus on. Yet, we can still argue for a certain cluster and motivate this using our findings above.\n",
    "\n",
    "## Conclusions\n",
    "- Most of the deaths from road accidents occur with drivers who have never been involved in any kind of road accident before. In other words, “first timers” in accidents are more likely to die.\n",
    "\n",
    "- This number is even higher for states belonging to cluster 1. \n",
    "\n",
    "\n",
    "## Suggestions\n",
    "- Extra measures should be taken to spread awareness about these statistics.\n",
    "- If people who’ve never been in an accident,  know that their chances of dying after an accident are SIGNIFICANTLY higher then they might take cautionary measures while driving.\n",
    "- Speed limits and traffic law should be strictly enforced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
